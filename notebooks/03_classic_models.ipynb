{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47eca92b",
   "metadata": {},
   "source": [
    "# 03_tfidf_classic_models (LogReg & Naive Bayes)\n",
    "\n",
    "Verwendet die von `02_preprocessing_variants.ipynb` erzeugten Dateien (vereinheitlichte Benennung ohne *tfidf_var*):\n",
    "- `cves_processed_text_raw.csv`\n",
    "- `cves_processed_text_clean.csv`\n",
    "- `cves_processed_text_raw_lemma.csv`\n",
    "- `cves_processed_text_clean_lemma.csv`\n",
    "\n",
    "Varianten unterscheiden sich durch Cleaning (Stopwörter/Normalisierung) und optionale Lemmatization. Dieses Notebook erlaubt nun die Auswahl einer einzelnen Variante (`VARIANT`) sowie einen optionalen Gesamtvergleich aller vorhandenen Varianten.\n",
    "\n",
    "Keine neuen Features – nur Training & Evaluation zweier klassischer Modelle (LogisticRegression, MultinomialNB) mit kombinierten Wort- und Zeichen-ngram TF-IDF Repräsentationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e542b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "WORD_VOCAB_MAX = 50000\n",
    "CHAR_VOCAB_MAX = 60000\n",
    "DATA_DIR = Path('../data/processed/')\n",
    "# Mögliche Varianten: 'raw', 'clean', 'raw_lemma', 'clean_lemma'\n",
    "VARIANT = 'clean'  # anpassen für Einzel-Lauf\n",
    "\n",
    "FILE_MAP = {\n",
    "    'raw': 'cves_processed_text_raw.csv',\n",
    "    'clean': 'cves_processed_text_clean.csv',\n",
    "    'raw_lemma': 'cves_processed_text_raw_lemma.csv',\n",
    "    'clean_lemma': 'cves_processed_text_clean_lemma.csv'\n",
    "}\n",
    "TEXT_COL_MAP = {\n",
    "    'raw': 'description_raw',\n",
    "    'clean': 'description_clean',\n",
    "    'raw_lemma': 'description_raw_lemma',\n",
    "    'clean_lemma': 'description_clean_lemma'\n",
    "}\n",
    "\n",
    "variant_file = DATA_DIR / FILE_MAP[VARIANT]\n",
    "assert variant_file.exists(), f\"Variant file missing: {variant_file}\"\n",
    "print({'variant': VARIANT, 'file': str(variant_file)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c047105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(variant_file)\n",
    "text_col = TEXT_COL_MAP[VARIANT]\n",
    "required_base = {'cve_id','severity','severity_id'}\n",
    "missing_base = required_base - set(df.columns)\n",
    "assert not missing_base, f'Missing columns: {missing_base}'\n",
    "assert text_col in df.columns, f'Text column {text_col} fehlt. Vorhanden: {df.columns.tolist()}'\n",
    "print('Shape (original):', df.shape)\n",
    "print('Klassenverteilung (original):', df['severity_id'].value_counts().to_dict())\n",
    "\n",
    "X = df[text_col].astype(str).values\n",
    "y = df['severity_id'].values\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "print({'train': len(X_train_text), 'test': len(X_test_text), 'text_col': text_col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    min_df=2,\n",
    "    max_features=WORD_VOCAB_MAX,\n",
    "    strip_accents='unicode',\n",
    "    lowercase=False,\n",
    "    sublinear_tf=True,\n",
    "    dtype=np.float32\n",
    ")\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    analyzer='char_wb',\n",
    "    ngram_range=(3,5),\n",
    "    min_df=2,\n",
    "    max_features=CHAR_VOCAB_MAX,\n",
    "    lowercase=False,\n",
    "    sublinear_tf=True,\n",
    "    dtype=np.float32\n",
    ")\n",
    "X_train_word = word_vectorizer.fit_transform(X_train_text)\n",
    "X_test_word = word_vectorizer.transform(X_test_text)\n",
    "X_train_char = char_vectorizer.fit_transform(X_train_text)\n",
    "X_test_char = char_vectorizer.transform(X_test_text)\n",
    "X_train = hstack([X_train_word, X_train_char]).tocsr()\n",
    "X_test = hstack([X_test_word, X_test_char]).tocsr()\n",
    "print({'X_train': X_train.shape, 'X_test': X_test.shape})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=500, solver='lbfgs', random_state=RANDOM_STATE)\n",
    "logreg.fit(X_train, y_train)\n",
    "log_preds = logreg.predict(X_test)\n",
    "log_acc = accuracy_score(y_test, log_preds)\n",
    "log_f1 = f1_score(y_test, log_preds, average='macro')\n",
    "results.append({'model': 'LogisticRegression', 'accuracy': log_acc, 'macro_f1': log_f1})\n",
    "print('LogReg:', {'accuracy': round(log_acc,4), 'macro_f1': round(log_f1,4)})\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_preds = nb.predict(X_test)\n",
    "nb_acc = accuracy_score(y_test, nb_preds)\n",
    "nb_f1 = f1_score(y_test, nb_preds, average='macro')\n",
    "results.append({'model': 'MultinomialNB', 'accuracy': nb_acc, 'macro_f1': nb_f1})\n",
    "print('MultinomialNB:', {'accuracy': round(nb_acc,4), 'macro_f1': round(nb_f1,4)})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print('\\nErgebnisübersicht:')\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = results_df.sort_values('macro_f1', ascending=False).iloc[0]\n",
    "print('\\nBestes Modell nach macro_f1:', best_row['model'])\n",
    "if best_row['model'] == 'LogisticRegression':\n",
    "    best_preds = log_preds\n",
    "else:\n",
    "    best_preds = nb_preds\n",
    "print(classification_report(y_test, best_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e8717",
   "metadata": {},
   "source": [
    "### 4.1 Evaluation ohne seltene Klassen\n",
    "Optional: Klassen mit sehr geringer Test-Support (unter `MIN_TEST_SUPPORT`) aus Metrikberechnung entfernen, um Warnungen zu vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f972d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from pathlib import Path as _Path\n",
    "\n",
    "VARIANT_LIST = ['raw','clean','raw_lemma','clean_lemma']\n",
    "comp_rows = []\n",
    "results_path_variants = _Path('../results/classic_variant_comparison.csv')\n",
    "\n",
    "for v in VARIANT_LIST:\n",
    "    f = DATA_DIR / FILE_MAP[v]\n",
    "    if not f.exists():\n",
    "        print(f\"[SKIP] Datei fehlt: {f}\")\n",
    "        continue\n",
    "    d = pd.read_csv(f)\n",
    "    tcol = TEXT_COL_MAP[v]\n",
    "    if tcol not in d.columns:\n",
    "        print(f\"[SKIP] Spalte {tcol} fehlt in {f.name}\")\n",
    "        continue\n",
    "    Xv = d[tcol].astype(str).values\n",
    "    yv = d['severity_id'].values\n",
    "    # Stratified split\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(Xv, yv, test_size=TEST_SIZE, stratify=yv, random_state=RANDOM_STATE)\n",
    "    # Vectorizer (gleiche Einstellungen wie Basislauf)\n",
    "    w_vec = TfidfVectorizer(ngram_range=(1,2), min_df=2, max_features=WORD_VOCAB_MAX, strip_accents='unicode', lowercase=False, sublinear_tf=True, dtype=np.float32)\n",
    "    c_vec = TfidfVectorizer(analyzer='char_wb', ngram_range=(3,5), min_df=2, max_features=CHAR_VOCAB_MAX, lowercase=False, sublinear_tf=True, dtype=np.float32)\n",
    "    t0 = time()\n",
    "    X_tr_w = w_vec.fit_transform(X_tr)\n",
    "    X_te_w = w_vec.transform(X_te)\n",
    "    X_tr_c = c_vec.fit_transform(X_tr)\n",
    "    X_te_c = c_vec.transform(X_te)\n",
    "    X_tr_all = hstack([X_tr_w, X_tr_c]).tocsr()\n",
    "    X_te_all = hstack([X_te_w, X_te_c]).tocsr()\n",
    "    vec_time = time() - t0\n",
    "\n",
    "    # Modelle\n",
    "    # LogReg\n",
    "    t1 = time()\n",
    "    lr_m = LogisticRegression(max_iter=500, solver='lbfgs', random_state=RANDOM_STATE)\n",
    "    lr_m.fit(X_tr_all, y_tr)\n",
    "    lr_preds = lr_m.predict(X_te_all)\n",
    "    lr_acc = accuracy_score(y_te, lr_preds)\n",
    "    lr_f1 = f1_score(y_te, lr_preds, average='macro')\n",
    "    comp_rows.append({'variant': v, 'model':'LogisticRegression', 'accuracy': lr_acc, 'macro_f1': lr_f1, 'vectorize_time_sec': vec_time})\n",
    "\n",
    "    # NB\n",
    "    nb_m = MultinomialNB()\n",
    "    nb_m.fit(X_tr_all, y_tr)\n",
    "    nb_preds = nb_m.predict(X_te_all)\n",
    "    nb_acc = accuracy_score(y_te, nb_preds)\n",
    "    nb_f1 = f1_score(y_te, nb_preds, average='macro')\n",
    "    comp_rows.append({'variant': v, 'model':'MultinomialNB', 'accuracy': nb_acc, 'macro_f1': nb_f1, 'vectorize_time_sec': vec_time})\n",
    "\n",
    "comp_df = pd.DataFrame(comp_rows)\n",
    "if not comp_df.empty:\n",
    "    display(comp_df.sort_values(['macro_f1','accuracy'], ascending=False))\n",
    "    try:\n",
    "        if results_path_variants.exists():\n",
    "            prev = pd.read_csv(results_path_variants)\n",
    "            comp_df = pd.concat([prev, comp_df], ignore_index=True)\n",
    "        comp_df.to_csv(results_path_variants, index=False)\n",
    "        print('Variant Vergleich gespeichert unter', results_path_variants)\n",
    "    except Exception as e:\n",
    "        print('Speichern fehlgeschlagen:', e)\n",
    "else:\n",
    "    print('Keine Varianten verarbeitet (Dateien/Spalten fehlen?).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb9df8e",
   "metadata": {},
   "source": [
    "### 4. Variant-Vergleich (optional)\n",
    "Dieser Abschnitt lädt alle verfügbaren Variantendateien (`raw`, `clean`, `raw_lemma`, `clean_lemma`) sofern vorhanden und führt ein schnelles Benchmarking beider Modelle durch. Er nutzt identische Vectorizer-Parameter wie der Basislauf (Wort 1-2gram, min_df=2, Char 3-5gram). Ergebnisse werden als DataFrame angezeigt und optional in `../results/classic_variant_comparison.csv` gespeichert.\n",
    "\n",
    "Überspringbar – hat keinen Einfluss auf den restlichen Ablauf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c109d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "MIN_TEST_SUPPORT = 5  # Schwellwert anpassen\n",
    "\n",
    "# Nutzt bereits berechnete best_preds & y_test\n",
    "test_support = Counter(y_test)\n",
    "# Mapping severity_id -> behalten?\n",
    "keep_labels = {lab for lab,count in test_support.items() if count >= MIN_TEST_SUPPORT}\n",
    "\n",
    "mask = [lab in keep_labels for lab in y_test]\n",
    "filtered_true = y_test[mask]\n",
    "if 'best_preds' in globals():\n",
    "    filtered_pred = np.array(best_preds)[mask]\n",
    "else:\n",
    "    filtered_pred = np.array([])\n",
    "\n",
    "print('Original Klassenanzahl:', len(test_support))\n",
    "print('Gefiltert (>= support):', len(keep_labels))\n",
    "print('Verworfene Klassen:', set(test_support.keys()) - keep_labels)\n",
    "\n",
    "if len(filtered_true) and len(np.unique(filtered_pred)):\n",
    "    print(classification_report(filtered_true, filtered_pred, zero_division=0, digits=4))\n",
    "else:\n",
    "    print('Zu wenige verbleibende Klassen oder keine Vorhersagen nach Filter.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ddcff6",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Grid & Logging\n",
    "Wir führen nun einen kleinen Grid über Wort/Char-Vectorizer Parameter (ngram_range, min_df, max_features) sowie LogReg-C und NB-alpha aus. Ergebnisse werden nach `results/classic_models_baseline.csv` appended. Spalte `variant` dokumentiert, welche Vorverarbeitungsvariante (inkl. evtl. Lemma) verwendet wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8851e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, json, os\n",
    "from itertools import product\n",
    "from pathlib import Path as _Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "RESULTS_DIR = _Path('../results')\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_PATH = RESULTS_DIR / 'classic_models_baseline.csv'\n",
    "\n",
    "# Re-use Original Daten (X_train_text, X_test_text, y_train, y_test)\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "word_ngrams_choices = [(1,1),(1,2)]\n",
    "char_ngrams_choices = [(3,5)]\n",
    "min_df_choices = [1,2]\n",
    "word_max_feats_choices = [20000, 50000]\n",
    "char_max_feats_choices = [30000]\n",
    "logreg_C_choices = [0.5, 1.0, 2.0]\n",
    "nb_alpha_choices = [0.5, 1.0]\n",
    "\n",
    "rows = []\n",
    "start_global = time.time()\n",
    "run_id_base = int(start_global)\n",
    "\n",
    "for (w_ng, c_ng, min_df, w_max, c_max) in product(word_ngrams_choices, char_ngrams_choices, min_df_choices, word_max_feats_choices, char_max_feats_choices):\n",
    "    # Vectorizer fit\n",
    "    word_vec = TfidfVectorizer(ngram_range=w_ng, min_df=min_df, max_features=w_max, strip_accents='unicode', lowercase=False, sublinear_tf=True, dtype=np.float32)\n",
    "    char_vec = TfidfVectorizer(analyzer='char_wb', ngram_range=c_ng, min_df=min_df, max_features=c_max, lowercase=False, sublinear_tf=True, dtype=np.float32)\n",
    "    t0 = time.time()\n",
    "    X_tr_w = word_vec.fit_transform(X_train_text)\n",
    "    X_te_w = word_vec.transform(X_test_text)\n",
    "    X_tr_c = char_vec.fit_transform(X_train_text)\n",
    "    X_te_c = char_vec.transform(X_test_text)\n",
    "    X_tr = hstack([X_tr_w, X_tr_c]).tocsr()\n",
    "    X_te = hstack([X_te_w, X_te_c]).tocsr()\n",
    "    vec_time = time.time() - t0\n",
    "\n",
    "    # Logistic Regression variations\n",
    "    for C in logreg_C_choices:\n",
    "        model_name = 'LogisticRegression'\n",
    "        logreg = LogisticRegression(max_iter=400, solver='lbfgs', C=C, n_jobs=None, random_state=RANDOM_STATE)\n",
    "        t1 = time.time()\n",
    "        logreg.fit(X_tr, y_train_enc)\n",
    "        train_time = time.time() - t1\n",
    "        preds = logreg.predict(X_te)\n",
    "        acc = accuracy_score(y_test_enc, preds)\n",
    "        f1 = f1_score(y_test_enc, preds, average='macro')\n",
    "        rows.append({\n",
    "            'run_id': run_id_base,\n",
    "            'timestamp': time.time(),\n",
    "            'model': model_name,\n",
    "            'variant': VARIANT,\n",
    "            'word_ngrams': str(w_ng),\n",
    "            'char_ngrams': str(c_ng),\n",
    "            'min_df': min_df,\n",
    "            'word_max_features': w_max,\n",
    "            'char_max_features': c_max,\n",
    "            'C': C,\n",
    "            'alpha': None,\n",
    "            'accuracy': acc,\n",
    "            'macro_f1': f1,\n",
    "            'vectorize_time_sec': vec_time,\n",
    "            'train_time_sec': train_time,\n",
    "            'n_train': X_tr.shape[0],\n",
    "            'n_test': X_te.shape[0],\n",
    "            'notes': ''\n",
    "        })\n",
    "\n",
    "    # Naive Bayes variations\n",
    "    for alpha in nb_alpha_choices:\n",
    "        model_name = 'MultinomialNB'\n",
    "        nb = MultinomialNB(alpha=alpha)\n",
    "        t1 = time.time()\n",
    "        nb.fit(X_tr, y_train_enc)\n",
    "        train_time = time.time() - t1\n",
    "        preds = nb.predict(X_te)\n",
    "        acc = accuracy_score(y_test_enc, preds)\n",
    "        f1 = f1_score(y_test_enc, preds, average='macro')\n",
    "        rows.append({\n",
    "            'run_id': run_id_base,\n",
    "            'timestamp': time.time(),\n",
    "            'model': model_name,\n",
    "            'variant': VARIANT,\n",
    "            'word_ngrams': str(w_ng),\n",
    "            'char_ngrams': str(c_ng),\n",
    "            'min_df': min_df,\n",
    "            'word_max_features': w_max,\n",
    "            'char_max_features': c_max,\n",
    "            'C': None,\n",
    "            'alpha': alpha,\n",
    "            'accuracy': acc,\n",
    "            'macro_f1': f1,\n",
    "            'vectorize_time_sec': vec_time,\n",
    "            'train_time_sec': train_time,\n",
    "            'n_train': X_tr.shape[0],\n",
    "            'n_test': X_te.shape[0],\n",
    "            'notes': ''\n",
    "        })\n",
    "\n",
    "results_grid_df = pd.DataFrame(rows)\n",
    "print('Grid Rows:', results_grid_df.shape)\n",
    "if RESULTS_PATH.exists():\n",
    "    prev = pd.read_csv(RESULTS_PATH)\n",
    "    results_grid_df = pd.concat([prev, results_grid_df], ignore_index=True)\n",
    "results_grid_df.to_csv(RESULTS_PATH, index=False)\n",
    "results_grid_df.sort_values('macro_f1', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e9fe2b",
   "metadata": {},
   "source": [
    "### 5.1 Feature Importance (Top Tokens)\n",
    "Extrahiert für das beste LogReg-Modell die höchsten positiven / negativen Koeffizienten je Klasse (falls LogReg im Grid enthalten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835d10fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rekonstruiere zuletzt im Grid verwendete word_vec / char_vec wenn LogReg vorhanden war\n",
    "# (Für vollständige Reproduzierbarkeit: separaten Fit mit besten Parametern durchführen.)\n",
    "from math import isfinite\n",
    "\n",
    "if 'results_grid_df' in globals():\n",
    "    # Bestes LogReg Modell bestimmen\n",
    "    best_lr_row = results_grid_df[results_grid_df['model']=='LogisticRegression'].sort_values('macro_f1', ascending=False).head(1)\n",
    "    if not best_lr_row.empty:\n",
    "        r = best_lr_row.iloc[0]\n",
    "        print('Best LogReg Params:', r.to_dict())\n",
    "        w_ng = eval(r['word_ngrams'])\n",
    "        c_ng = eval(r['char_ngrams'])\n",
    "        min_df = int(r['min_df'])\n",
    "        w_max = int(r['word_max_features']) if isfinite(r['word_max_features']) else None\n",
    "        c_max = int(r['char_max_features']) if isfinite(r['char_max_features']) else None\n",
    "        C = float(r['C']) if r['C'] else 1.0\n",
    "\n",
    "        # Refit für transparente Pipeline\n",
    "        word_vec_best = TfidfVectorizer(ngram_range=w_ng, min_df=min_df, max_features=w_max, strip_accents='unicode', lowercase=False, sublinear_tf=True, dtype=np.float32)\n",
    "        char_vec_best = TfidfVectorizer(analyzer='char_wb', ngram_range=c_ng, min_df=min_df, max_features=c_max, lowercase=False, sublinear_tf=True, dtype=np.float32)\n",
    "        X_tr_w_best = word_vec_best.fit_transform(X_train_text)\n",
    "        X_te_w_best = word_vec_best.transform(X_test_text)\n",
    "        X_tr_c_best = char_vec_best.fit_transform(X_train_text)\n",
    "        X_te_c_best = char_vec_best.transform(X_test_text)\n",
    "        X_tr_best = hstack([X_tr_w_best, X_tr_c_best]).tocsr()\n",
    "        X_te_best = hstack([X_te_w_best, X_te_c_best]).tocsr()\n",
    "\n",
    "        logreg_best = LogisticRegression(max_iter=400, solver='lbfgs', C=C, random_state=RANDOM_STATE)\n",
    "        logreg_best.fit(X_tr_best, y_train_enc)\n",
    "\n",
    "        feature_names = list(word_vec_best.get_feature_names_out()) + list(char_vec_best.get_feature_names_out())\n",
    "        coefs = logreg_best.coef_  # shape [n_classes, n_features]\n",
    "        top_k = 15\n",
    "        class_importance = {}\n",
    "        for class_index, class_label in enumerate(le.classes_):\n",
    "            weights = coefs[class_index]\n",
    "            top_pos_idx = np.argsort(weights)[-top_k:][::-1]\n",
    "            top_neg_idx = np.argsort(weights)[:top_k]\n",
    "            class_importance[int(class_label)] = {\n",
    "                'top_positive': [(feature_names[i], float(weights[i])) for i in top_pos_idx],\n",
    "                'top_negative': [(feature_names[i], float(weights[i])) for i in top_neg_idx]\n",
    "            }\n",
    "        import json\n",
    "        imp_path = _Path('../results/logreg_feature_importance.json')\n",
    "        with open(imp_path, 'w') as f:\n",
    "            json.dump(class_importance, f, indent=2)\n",
    "        print('Feature Importance gespeichert unter', imp_path)\n",
    "    else:\n",
    "        print('Kein LogReg Ergebnis im Grid gefunden.')\n",
    "else:\n",
    "    print('results_grid_df nicht definiert - Grid vorher ausführen.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3592418",
   "metadata": {},
   "source": [
    "## 6. Visualisierungen & Analyse\n",
    "\n",
    "In diesem Abschnitt werden Ergebnisse aus dem Grid und Feature-Importances visualisiert:\n",
    "\n",
    "- Modellvergleich (Accuracy, Macro-F1)\n",
    "- Hyperparameter-Einflüsse (C, alpha, min_df, ngram_range)\n",
    "- LogReg Feature Importance (Top Tokens je Klasse als Balken)\n",
    "- Naive Bayes Top-Wörter (log P(token|class) Differenzen)\n",
    "\n",
    "Jede Zelle prüft Vorbedingungen, damit das Notebook auch bei teilweise fehlenden Artefakten läuft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689faf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Modellvergleich (Balkendiagramme)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path as _Path\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "if 'results_grid_df' not in globals():\n",
    "    path = _Path('../results/classic_models_baseline.csv')\n",
    "    if path.exists():\n",
    "        results_grid_df = pd.read_csv(path)\n",
    "    else:\n",
    "        print('Keine Grid-Ergebnisse gefunden. Abschnitt übersprungen.')\n",
    "\n",
    "if 'results_grid_df' in globals():\n",
    "    # Aggregiere bestes Ergebnis je Modell\n",
    "    best_per_model = results_grid_df.sort_values('macro_f1', ascending=False).groupby('model', as_index=False).first()\n",
    "    display(best_per_model[['model','accuracy','macro_f1']])\n",
    "\n",
    "    fig, axes = plt.subplots(1,2, figsize=(10,4))\n",
    "    # Verwende hue=model + legend=False, damit zukünftige seaborn Versionen kein Warning werfen\n",
    "    sns.barplot(data=best_per_model, x='model', y='accuracy', hue='model', ax=axes[0], palette='Blues_d', legend=False)\n",
    "    axes[0].set_title('Accuracy (best pro Modell)')\n",
    "    sns.barplot(data=best_per_model, x='model', y='macro_f1', hue='model', ax=axes[1], palette='Greens_d', legend=False)\n",
    "    axes[1].set_title('Macro-F1 (best pro Modell)')\n",
    "    for ax in axes:\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(f\"{p.get_height():.3f}\", (p.get_x()+p.get_width()/2, p.get_height()), ha='center', va='bottom', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    print('results_grid_df nicht verfügbar.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a38250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Hyperparameter-Einflüsse (nur LogReg & NB separat)\n",
    "if 'results_grid_df' in globals():\n",
    "    df_hp = results_grid_df.copy()\n",
    "    # Wort-Ngram Range als String -> vereinfachen\n",
    "    df_hp['word_ngrams'] = df_hp['word_ngrams'].astype(str)\n",
    "    df_hp['char_ngrams'] = df_hp['char_ngrams'].astype(str)\n",
    "\n",
    "    fig, axes = plt.subplots(2,2, figsize=(12,8))\n",
    "    # C vs Macro-F1 (LogReg)\n",
    "    lr_df = df_hp[df_hp['model']=='LogisticRegression'].dropna(subset=['C'])\n",
    "    if not lr_df.empty:\n",
    "        sns.lineplot(data=lr_df, x='C', y='macro_f1', marker='o', ax=axes[0,0])\n",
    "        axes[0,0].set_title('LogReg: C vs Macro-F1')\n",
    "    else:\n",
    "        axes[0,0].text(0.5,0.5,'Keine LogReg Daten', ha='center')\n",
    "\n",
    "    # alpha vs Macro-F1 (NB)\n",
    "    nb_df = df_hp[df_hp['model']=='MultinomialNB'].dropna(subset=['alpha'])\n",
    "    if not nb_df.empty:\n",
    "        sns.lineplot(data=nb_df, x='alpha', y='macro_f1', marker='o', color='orange', ax=axes[0,1])\n",
    "        axes[0,1].set_title('NaiveBayes: alpha vs Macro-F1')\n",
    "    else:\n",
    "        axes[0,1].text(0.5,0.5,'Keine NB Daten', ha='center')\n",
    "\n",
    "    # min_df Effekt (aggregiert best per setting)\n",
    "    agg_min_df = df_hp.sort_values('macro_f1', ascending=False).groupby(['model','min_df'], as_index=False).first()\n",
    "    sns.barplot(data=agg_min_df, x='min_df', y='macro_f1', hue='model', ax=axes[1,0])\n",
    "    axes[1,0].set_title('min_df Effekt (best per model & min_df)')\n",
    "\n",
    "    # ngram range Effekt (word)\n",
    "    agg_ng = df_hp.sort_values('macro_f1', ascending=False).groupby(['model','word_ngrams'], as_index=False).first()\n",
    "    sns.barplot(data=agg_ng, x='word_ngrams', y='macro_f1', hue='model', ax=axes[1,1])\n",
    "    axes[1,1].set_title('Word ngram_range Effekt')\n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    print('results_grid_df nicht verfügbar für Hyperparameter-Plots.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fdf07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 LogReg Feature Importance Visualisierung\n",
    "import json\n",
    "from math import isfinite\n",
    "\n",
    "imp_json_path = _Path('../results/logreg_feature_importance.json')\n",
    "if imp_json_path.exists():\n",
    "    with open(imp_json_path) as f:\n",
    "        imp_data = json.load(f)\n",
    "    n_classes = len(imp_data)\n",
    "    fig, axes = plt.subplots(n_classes, 2, figsize=(10, 3*n_classes))\n",
    "    if n_classes == 1:\n",
    "        axes = np.array([axes])\n",
    "    for idx, (cls, val) in enumerate(sorted(imp_data.items(), key=lambda x: int(x[0]))):\n",
    "        pos = val['top_positive']\n",
    "        neg = val['top_negative']\n",
    "        pos_df = pd.DataFrame(pos, columns=['token','weight']).sort_values('weight')\n",
    "        neg_df = pd.DataFrame(neg, columns=['token','weight']).sort_values('weight')\n",
    "        # Variante 1: ohne palette, default Farben\n",
    "        sns.barplot(data=pos_df, x='weight', y='token', hue='token', dodge=False, legend=False, ax=axes[idx,0])\n",
    "        axes[idx,0].set_title(f'Class {cls} Top Positive')\n",
    "        sns.barplot(data=neg_df, x='weight', y='token', hue='token', dodge=False, legend=False, ax=axes[idx,1])\n",
    "        axes[idx,1].set_title(f'Class {cls} Top Negative')\n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    print('Keine logreg_feature_importance.json gefunden. Vorher Section 5.1 ausführen.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4 Naive Bayes Top Tokens\n",
    "# Erneuter Fit des besten NB Modells anhand Grid (analog zu LogReg Importance)\n",
    "if 'results_grid_df' in globals():\n",
    "    best_nb_row = results_grid_df[results_grid_df['model']=='MultinomialNB'].sort_values('macro_f1', ascending=False).head(1)\n",
    "    if not best_nb_row.empty:\n",
    "        r = best_nb_row.iloc[0]\n",
    "        print('Best NB Params:', r.to_dict())\n",
    "        from math import isfinite\n",
    "        w_ng = eval(r['word_ngrams'])\n",
    "        c_ng = eval(r['char_ngrams'])\n",
    "        min_df = int(r['min_df'])\n",
    "        w_max = int(r['word_max_features']) if isfinite(r['word_max_features']) else None\n",
    "        c_max = int(r['char_max_features']) if isfinite(r['char_max_features']) else None\n",
    "        alpha = float(r['alpha']) if r['alpha'] else 1.0\n",
    "\n",
    "        word_vec_nb = TfidfVectorizer(ngram_range=w_ng, min_df=min_df, max_features=w_max, strip_accents='unicode', lowercase=False, sublinear_tf=True, dtype=np.float32)\n",
    "        char_vec_nb = TfidfVectorizer(analyzer='char_wb', ngram_range=c_ng, min_df=min_df, max_features=c_max, lowercase=False, sublinear_tf=True, dtype=np.float32)\n",
    "        X_tr_w_nb = word_vec_nb.fit_transform(X_train_text)\n",
    "        X_te_w_nb = word_vec_nb.transform(X_test_text)\n",
    "        X_tr_c_nb = char_vec_nb.fit_transform(X_train_text)\n",
    "        X_te_c_nb = char_vec_nb.transform(X_test_text)\n",
    "        X_tr_nb = hstack([X_tr_w_nb, X_tr_c_nb]).tocsr()\n",
    "        X_te_nb = hstack([X_te_w_nb, X_te_c_nb]).tocsr()\n",
    "\n",
    "        nb_best = MultinomialNB(alpha=alpha)\n",
    "        nb_best.fit(X_tr_nb, y_train_enc)\n",
    "\n",
    "        feature_names_nb = list(word_vec_nb.get_feature_names_out()) + list(char_vec_nb.get_feature_names_out())\n",
    "        log_prob = nb_best.feature_log_prob_  # shape [n_classes, n_features]\n",
    "        top_k = 15\n",
    "\n",
    "        fig, axes = plt.subplots(len(le.classes_), 1, figsize=(10, 3*len(le.classes_)))\n",
    "        if len(le.classes_) == 1:\n",
    "            axes = [axes]\n",
    "        nb_tokens_export = {}\n",
    "        for idx, class_label in enumerate(le.classes_):\n",
    "            weights = log_prob[idx]\n",
    "            top_idx = np.argsort(weights)[-top_k:][::-1]\n",
    "            top_tokens = [(feature_names_nb[i], float(weights[i])) for i in top_idx]\n",
    "            nb_tokens_export[int(class_label)] = top_tokens\n",
    "            plot_df = pd.DataFrame(top_tokens, columns=['token','log_prob']).sort_values('log_prob')\n",
    "            sns.barplot(data=plot_df, x='log_prob', y='token', hue='token', dodge=False, legend=False, ax=axes[idx])\n",
    "            axes[idx].set_title(f'NB log P(token|class={class_label}) Top {top_k}')\n",
    "        plt.tight_layout()\n",
    "        out_path = _Path('../results/nb_feature_logprob.json')\n",
    "        with open(out_path, 'w') as f:\n",
    "            json.dump(nb_tokens_export, f, indent=2)\n",
    "        print('NB Token Log-Prob exportiert nach', out_path)\n",
    "    else:\n",
    "        print('Kein NB Modell im Grid gefunden.')\n",
    "else:\n",
    "    print('results_grid_df nicht verfügbar – Grid zuerst ausführen.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
